{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFuL-RBgXqgU"
   },
   "source": [
    "In this notebook, we will build an abstractive based text summarizer using deep learning from the scratch in python using keras\n",
    "\n",
    "I recommend you to go through the article over [here](https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/) to cover all the concepts which is required to build our own summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5dSoP8lGMZi"
   },
   "source": [
    "#Understanding the Problem Statement\n",
    "\n",
    "Customer reviews can often be long and descriptive. Analyzing these reviews manually, as you can imagine, is really time-consuming. This is where the brilliance of Natural Language Processing can be applied to generate a summary for long reviews.\n",
    "\n",
    "We will be working on a really cool dataset. Our objective here is to generate a summary for the Amazon Fine Food reviews using the abstraction-based approach we learned about above. You can download the dataset from[ here ](https://www.kaggle.com/snap/amazon-fine-food-reviews)\n",
    "\n",
    "It’s time to fire up our Jupyter notebooks! Let’s dive into the implementation details right away.\n",
    "\n",
    "#Custom Attention Layer\n",
    "\n",
    "Keras does not officially support attention layer. So, we can either implement our own attention layer or use a third-party implementation. We will go with the latter option for this article. You can download the attention layer from [here](https://github.com/thushv89/attention_keras/blob/master/layers/attention.py) and copy it in a different file called attention.py.\n",
    "\n",
    "Let’s import it into our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fi64aA0FFxcS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from Attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUValOzcHtEK"
   },
   "source": [
    "#Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "_Jpu8qLEFxcY",
    "outputId": "95968e01-faac-4911-c802-9c008a4e62cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UVakjZ3oICgx"
   },
   "source": [
    "#Read the dataset\n",
    "\n",
    "This dataset consists of reviews of fine foods from Amazon. The data spans a period of more than 10 years, including all ~500,000 reviews up to October 2012. These reviews include product and user information, ratings, plain text review, and summary. It also includes reviews from all other Amazon categories.\n",
    "\n",
    "We’ll take a sample of 100,000 reviews to reduce the training time of our model. Feel free to use the entire dataset for training your model if your machine has that kind of computational power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnK5o4Z1Fxcj"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Reviews.csv\",nrows=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGNQKvCaISIn"
   },
   "source": [
    "# Drop Duplicates and NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cjul88oOFxcr"
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
    "data.dropna(axis=0,inplace=True)#dropping na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qi0xD6BkIWAm"
   },
   "source": [
    "# Information about dataset\n",
    "\n",
    "Let us look at datatypes and shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__fy-JxTFxc9",
    "outputId": "d42c6e36-bbc8-43c2-de0e-d3effe3e8c4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 88421 entries, 0 to 99999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Id                      88421 non-null  int64 \n",
      " 1   ProductId               88421 non-null  object\n",
      " 2   UserId                  88421 non-null  object\n",
      " 3   ProfileName             88421 non-null  object\n",
      " 4   HelpfulnessNumerator    88421 non-null  int64 \n",
      " 5   HelpfulnessDenominator  88421 non-null  int64 \n",
      " 6   Score                   88421 non-null  int64 \n",
      " 7   Time                    88421 non-null  int64 \n",
      " 8   Summary                 88421 non-null  object\n",
      " 9   Text                    88421 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0xLYACiFxdJ"
   },
   "source": [
    "#Preprocessing\n",
    "\n",
    "Performing basic preprocessing steps is very important before we get to the model building part. Using messy and uncleaned text data is a potentially disastrous move. So in this step, we will drop all the unwanted symbols, characters, etc. from the text that do not affect the objective of our problem.\n",
    "\n",
    "Here is the dictionary that we will use for expanding the contractions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0s6IY-x2FxdL"
   },
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JFRXFHmI7Mj"
   },
   "source": [
    "We will perform the below preprocessing tasks for our data:\n",
    "\n",
    "1.Convert everything to lowercase\n",
    "\n",
    "2.Remove HTML tags\n",
    "\n",
    "3.Contraction mapping\n",
    "\n",
    "4.Remove (‘s)\n",
    "\n",
    "5.Remove any text inside the parenthesis ( )\n",
    "\n",
    "6.Eliminate punctuations and special characters\n",
    "\n",
    "7.Remove stopwords\n",
    "\n",
    "8.Remove short words\n",
    "\n",
    "Let’s define the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZr-u3OEFxdT"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2QAeCHWFxdY"
   },
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t,0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "snRZY8wjLao2"
   },
   "source": [
    "Let us look at the first five preprocessed reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCAIkhWbFxdh",
    "outputId": "c2da1a36-4488-4e32-ef9e-fcfe496e374d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:5]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GsRXocxoFxd-"
   },
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(text_cleaner(t,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZeD0gs6Lnb-"
   },
   "source": [
    "Let us look at the first 10 preprocessed summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQJdZcAzFxee",
    "outputId": "a1fbe683-c03f-4afb-addf-e075021c121b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine',\n",
       " 'great taffy',\n",
       " 'nice taffy',\n",
       " 'great just as good as the expensive brands',\n",
       " 'wonderful tasty taffy',\n",
       " 'yay barley',\n",
       " 'healthy dog food']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_summary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1zLpnqsFxey"
   },
   "outputs": [],
   "source": [
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KT_D2cLiLy77"
   },
   "source": [
    "#Drop empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYK390unFxfA"
   },
   "outputs": [],
   "source": [
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vm8Fk2TCL7Sp"
   },
   "source": [
    "#Understanding the distribution of the sequences\n",
    "\n",
    "Here, we will analyze the length of the reviews and the summary to get an overall idea about the distribution of length of the text. This will help us fix the maximum length of the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdF76AHHFxgw",
    "outputId": "e3bbe165-4235-482f-bfd4-36a3f1d95290"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwdSGIhGMEbz"
   },
   "source": [
    "Interesting. We can fix the maximum length of the summary to 8 since that seems to be the majority summary length.\n",
    "\n",
    "Let us understand the proportion of the length of summaries below 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7JRjwdIOFxg3",
    "outputId": "f968be82-c539-471d-ce23-16f18b059ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9424907471335922\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in data['cleaned_summary']:\n",
    "    if(len(i.split())<=8):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(data['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yYB4Ga9KMjEu"
   },
   "source": [
    "We observe that 94% of the summaries have length below 8. So, we can fix maximum length of summary to 8.\n",
    "\n",
    "Let us fix the maximum length of review to 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKD5VOWqFxhC"
   },
   "outputs": [],
   "source": [
    "max_text_len=30\n",
    "max_summary_len=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E6d48E-8M4VO"
   },
   "source": [
    "Let us select the reviews and summaries whose length falls below or equal to **max_text_len** and **max_summary_len**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yY0tEJP0FxhI"
   },
   "outputs": [],
   "source": [
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "cleaned_summary=np.array(data['cleaned_summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tR1uh8xSNUma"
   },
   "source": [
    "Remember to add the **START** and **END** special tokens at the beginning and end of the summary. Here, I have chosen **sostok** and **eostok** as START and END tokens\n",
    "\n",
    "**Note:** Be sure that the chosen special tokens never appear in the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EwLUH78CFxhg"
   },
   "outputs": [],
   "source": [
    "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1GlcX4RFOh13"
   },
   "source": [
    "We are getting closer to the model building part. Before that, we need to split our dataset into a training and validation set. We’ll use 90% of the dataset as the training data and evaluate the performance on the remaining 10% (holdout set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RakakKHcFxhl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vq1mqyOHOtIl"
   },
   "source": [
    "#Preparing the Tokenizer\n",
    "\n",
    "A tokenizer builds the vocabulary and converts a word sequence to an integer sequence. Go ahead and build tokenizers for text and summary:\n",
    "\n",
    "#Text Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oRHTgX6hFxhq"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RzvLwYL_PDcx"
   },
   "source": [
    "#Rarewords and its Coverage\n",
    "\n",
    "Let us look at the proportion rare words and its total coverage in the entire text\n",
    "\n",
    "Here, I am defining the threshold to be 4 which means word whose count is below 4 is considered as a rare word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8KronV2Fxhx",
    "outputId": "d2eb2f27-fbbc-4e61-9556-3c3ff5e4327b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 65.97564857552125\n",
      "Total Coverage of rare words: 2.8991648882584453\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "So-J-5kzQIeO"
   },
   "source": [
    "**Remember**:\n",
    "\n",
    "\n",
    "* **tot_cnt** gives the size of vocabulary (which means every unique words in the text)\n",
    " \n",
    "*   **cnt** gives me the no. of rare words whose count falls below threshold\n",
    "\n",
    "*  **tot_cnt - cnt** gives me the top most common words \n",
    "\n",
    "Let us define the tokenizer with top most common words for reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2giEsF3Fxh3"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCbGMsm4FxiA",
    "outputId": "2d9165f0-e542-4114-91f3-e070d483fce9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8552"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQfKP3sqRxi9"
   },
   "source": [
    "#Summary Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRHqyBkBFxiJ"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KInA6O6ZSkJz"
   },
   "source": [
    "#Rarewords and its Coverage\n",
    "\n",
    "Let us look at the proportion rare words and its total coverage in the entire summary\n",
    "\n",
    "Here, I am defining the threshold to be 6 which means word whose count is below 6 is considered as a rare word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yzE5OiRLFxiM",
    "outputId": "7f7a4f89-b088-4847-8172-09e5a2383d0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 77.86357786357786\n",
      "Total Coverage of rare words: 5.280070297558538\n"
     ]
    }
   ],
   "source": [
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0PBhzKuRSw_9"
   },
   "source": [
    "Let us define the tokenizer with top most common words for summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-fswLvIgFxiR"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqwDUT5oTFmn"
   },
   "source": [
    "Let us check whether word count of start token is equal to length of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pR8IX9FRFxiY",
    "outputId": "b116cdbd-42c4-4ede-9f6d-46284115393e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43304, 43304)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_counts['sostok'],len(y_tr)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LVFhFVguTTtw"
   },
   "source": [
    "Here, I am deleting the rows that contain only **START** and **END** tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZ-vW82sFxih"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cx5NISuMFxik"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wOtlDcthFxip"
   },
   "source": [
    "# Model building\n",
    "\n",
    "We are finally at the model building part. But before we do that, we need to familiarize ourselves with a few terms which are required prior to building the model.\n",
    "\n",
    "**Return Sequences = True**: When the return sequences parameter is set to True, LSTM produces the hidden state and cell state for every timestep\n",
    "\n",
    "**Return State = True**: When return state = True, LSTM produces the hidden state and cell state of the last timestep only\n",
    "\n",
    "**Initial State**: This is used to initialize the internal states of the LSTM for the first timestep\n",
    "\n",
    "**Stacked LSTM**: Stacked LSTM has multiple layers of LSTM stacked on top of each other. \n",
    "This leads to a better representation of the sequence. I encourage you to experiment with the multiple layers of the LSTM stacked on top of each other (it’s a great way to learn this)\n",
    "\n",
    "Here, we are building a 3 stacked LSTM for the encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXef38nBFxir",
    "outputId": "7ae99521-46f8-4c6f-9cba-4979deffeee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Shantanu\\Anaconda3\\envs\\TXTSUMG\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method AttentionLayer.call of <Attention.AttentionLayer object at 0x0000018D8B69DD68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <Attention.AttentionLayer object at 0x0000018D8B69DD68>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionLayer.call of <Attention.AttentionLayer object at 0x0000018D8B69DD68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <Attention.AttentionLayer object at 0x0000018D8B69DD68>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 200)      1710400     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 30, 300), (N 601200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 30, 300), (N 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 200)    413000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 30, 300), (N 721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 300),  601200      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 2065)   1241065     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,189,565\n",
      "Trainable params: 6,189,565\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=200\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ZVlfRuMUcoP"
   },
   "source": [
    "I am using sparse categorical cross-entropy as the loss function since it converts the integer sequence to a one-hot vector on the fly. This overcomes any memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lwfi1Fm8Fxiz"
   },
   "outputs": [],
   "source": [
    "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer='RMSProp', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0ykDbxfUhyw"
   },
   "source": [
    "Remember the concept of early stopping? It is used to stop training the neural network at the right time by monitoring a user-specified metric. Here, I am monitoring the validation loss (val_loss). Our model will stop training once the validation loss increases:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-A3J92MUljB"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mw6CVECaUq5b"
   },
   "source": [
    "We’ll train the model on a batch size of 128 and validate it on the holdout set (which is 10% of our dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ETnPzA4OFxi3",
    "outputId": "477e374f-7cf2-4d60-f86e-2c49c9cebedb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42215 samples, validate on 4679 samples\n",
      "Epoch 1/100\n",
      "42215/42215 [==============================] - 43s 1ms/sample - loss: 2.1351 - acc: 0.6707 - val_loss: 2.0348 - val_acc: 0.6788\n",
      "Epoch 2/100\n",
      "42215/42215 [==============================] - 40s 956us/sample - loss: 1.9803 - acc: 0.6809 - val_loss: 1.8971 - val_acc: 0.6861\n",
      "Epoch 3/100\n",
      "42215/42215 [==============================] - 40s 957us/sample - loss: 1.8702 - acc: 0.6887 - val_loss: 1.8156 - val_acc: 0.6937\n",
      "Epoch 4/100\n",
      "42215/42215 [==============================] - 40s 956us/sample - loss: 1.7914 - acc: 0.6948 - val_loss: 1.7649 - val_acc: 0.6978\n",
      "Epoch 5/100\n",
      "42215/42215 [==============================] - 40s 959us/sample - loss: 1.7346 - acc: 0.6995 - val_loss: 1.7321 - val_acc: 0.7014\n",
      "Epoch 6/100\n",
      "42215/42215 [==============================] - 40s 959us/sample - loss: 1.6894 - acc: 0.7030 - val_loss: 1.7041 - val_acc: 0.7052\n",
      "Epoch 7/100\n",
      "42215/42215 [==============================] - 41s 972us/sample - loss: 1.6489 - acc: 0.7060 - val_loss: 1.6858 - val_acc: 0.7056\n",
      "Epoch 8/100\n",
      "42215/42215 [==============================] - 41s 960us/sample - loss: 1.6138 - acc: 0.7085 - val_loss: 1.6672 - val_acc: 0.7071\n",
      "Epoch 9/100\n",
      "42215/42215 [==============================] - 40s 958us/sample - loss: 1.5803 - acc: 0.7114 - val_loss: 1.6540 - val_acc: 0.7089\n",
      "Epoch 10/100\n",
      "42215/42215 [==============================] - 40s 959us/sample - loss: 1.5508 - acc: 0.7137 - val_loss: 1.6442 - val_acc: 0.7099\n",
      "Epoch 11/100\n",
      "42215/42215 [==============================] - 41s 960us/sample - loss: 1.5231 - acc: 0.7159 - val_loss: 1.6403 - val_acc: 0.7108\n",
      "Epoch 12/100\n",
      "42215/42215 [==============================] - 41s 960us/sample - loss: 1.4976 - acc: 0.7177 - val_loss: 1.6341 - val_acc: 0.7114\n",
      "Epoch 13/100\n",
      "42215/42215 [==============================] - 40s 959us/sample - loss: 1.4736 - acc: 0.7198 - val_loss: 1.6277 - val_acc: 0.7120\n",
      "Epoch 14/100\n",
      "42215/42215 [==============================] - 40s 959us/sample - loss: 1.4499 - acc: 0.7215 - val_loss: 1.6300 - val_acc: 0.7113\n",
      "Epoch 15/100\n",
      "42215/42215 [==============================] - 41s 959us/sample - loss: 1.4283 - acc: 0.7234 - val_loss: 1.6270 - val_acc: 0.7119\n",
      "Epoch 16/100\n",
      "42215/42215 [==============================] - 41s 960us/sample - loss: 1.4079 - acc: 0.7250 - val_loss: 1.6221 - val_acc: 0.7123\n",
      "Epoch 17/100\n",
      "42215/42215 [==============================] - 41s 961us/sample - loss: 1.3867 - acc: 0.7266 - val_loss: 1.6252 - val_acc: 0.7125\n",
      "Epoch 18/100\n",
      "42215/42215 [==============================] - 41s 960us/sample - loss: 1.3674 - acc: 0.7288 - val_loss: 1.6244 - val_acc: 0.7127\n",
      "Epoch 19/100\n",
      "42215/42215 [==============================] - 41s 961us/sample - loss: 1.3485 - acc: 0.7302 - val_loss: 1.6301 - val_acc: 0.7140\n",
      "Epoch 20/100\n",
      "42215/42215 [==============================] - 41s 960us/sample - loss: 1.3300 - acc: 0.7317 - val_loss: 1.6285 - val_acc: 0.7129\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:],\n",
    "                  epochs=100,\n",
    "                  callbacks=[es],\n",
    "                  batch_size=256, \n",
    "                  validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ezKYOp2UxG5"
   },
   "source": [
    "#Understanding the Diagnostic plot\n",
    "\n",
    "Now, we will plot a few diagnostic plots to understand the behavior of the model over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tDTNLAURFxjE",
    "outputId": "e2ea6e44-3931-4014-97a1-03fa2a441228"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSyx-HvpUz2o"
   },
   "source": [
    "From the plot, we can infer that validation loss has increased after epoch 17 for 2 successive epochs. Hence, training is stopped at epoch 19.\n",
    "\n",
    "Next, let’s build the dictionary to convert the index to word for target and source vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sBX0zZnOFxjW"
   },
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eM_nU_VvFxjq"
   },
   "source": [
    "# Inference\n",
    "\n",
    "Set up the inference for the encoder and decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9QkrNV-4Fxjt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method AttentionLayer.call of <Attention.AttentionLayer object at 0x0000018D8B69DD68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <Attention.AttentionLayer object at 0x0000018D8B69DD68>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionLayer.call of <Attention.AttentionLayer object at 0x0000018D8B69DD68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <Attention.AttentionLayer object at 0x0000018D8B69DD68>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    }
   ],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOiyk4ToWe74"
   },
   "source": [
    "We are defining a function below which is the implementation of the inference process (which we covered [here](https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6f6TTFnBFxj6"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6GuDf4TPWt6_"
   },
   "source": [
    "Let us define the functions to convert an integer sequence to a word sequence for summary as well as the reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAUntznIFxj9"
   },
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9gM4ALyfWwA9"
   },
   "source": [
    "Here are a few summaries generated by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BUtQmQTmFxkI",
    "outputId": "f407d9fc-e0cd-4082-98f5-bd1f562dc26f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: purchased product christmas gift assumed coming bellagio would perfect person gave tried one packet gave rest away said smelled great tasted chalky would drink \n",
      "Original summary: chocolate truffle \n",
      "Predicted summary:  just ok\n",
      "\n",
      "\n",
      "Review: nice quality looking keep bamboo salt keeper swing open cover grab pinch like minerals instead additives \n",
      "Original summary: nice quality \n",
      "Predicted summary:  good product\n",
      "\n",
      "\n",
      "Review: eat gluten free wonder snack crackers wonderful tried find tasty snacks hard find however crackers good \n",
      "Original summary: eating gluten free \n",
      "Predicted summary:  great gluten free snack\n",
      "\n",
      "\n",
      "Review: great source essential fatty acids without unpleasant tasting fish oil flax seed oil also agree stomach also think helps ibs symptoms \n",
      "Original summary: great alternative to flax or fish oil \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: anything really exciting little sweet kids like relatively healthy stays crunchy continue buy kids \n",
      "Original summary: crunchy little too sweet \n",
      "Predicted summary:  great snack\n",
      "\n",
      "\n",
      "Review: use syrup create coffee signature drink caf carmel perfect ounce two syrup oz coffee top whipped cream sprinkles ghirardelli delicious savings \n",
      "Original summary: coffee \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: found flavor store searched forever find went amazon purchased little afraid buying food amazon fear like buy store could find cheaper amazon \n",
      "Original summary: pop tarts roll flavor \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: really like product always fresh taste great especially like lid easy use secure like brands flip lid tears easily leak \n",
      "Original summary: it is great \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: cute idea would made great christmas gift pretzels million pieces dozen recognizable christmas shape needs way better packing guess making lot pretzel crusted chicken \n",
      "Original summary: cute idea but \n",
      "Predicted summary:  not as pictured\n",
      "\n",
      "\n",
      "Review: dogs love actually little dance settling eat way three stars well way much packaging emails cs letter gone \n",
      "Original summary: product vs packaging \n",
      "Predicted summary:  my dogs love it\n",
      "\n",
      "\n",
      "Review: basket smaller anticipated price bought disappointed also came different basket shown \n",
      "Original summary: basket for \n",
      "Predicted summary:  nice gift\n",
      "\n",
      "\n",
      "Review: strong tasting bar sweet tasting close eat large drink seem satisfying afternoon snack \n",
      "Original summary: bar \n",
      "Predicted summary:  great snack\n",
      "\n",
      "\n",
      "Review: great training break small bits since soft dogs picky never turned one \n",
      "Original summary: dogs love them \n",
      "Predicted summary:  great treats\n",
      "\n",
      "\n",
      "Review: since purchase cooks bread machine also great item using bread mix best market opinion \n",
      "Original summary: best bread mix we have tried \n",
      "Predicted summary:  pamela bread mix\n",
      "\n",
      "\n",
      "Review: excited find cherries husband loves disappointed old tasting would order \n",
      "Original summary: disappointed \n",
      "Predicted summary:  not the best\n",
      "\n",
      "\n",
      "Review: product healthy snack kids homework time mixture sweet salty hits spot till next meal \n",
      "Original summary: great snack \n",
      "Predicted summary:  great snack\n",
      "\n",
      "\n",
      "Review: use like noodles good eat easy prepare quickly kids love use replace top oriental style stir fry soup sodium calories combine well meat veggies great compliment gluten free diet \n",
      "Original summary: good food easy and quick \n",
      "Predicted summary:  great for gluten free baking\n",
      "\n",
      "\n",
      "Review: recently bought green tea wanted try something plain green tea glad ginseng honey lemon add great flavor four bags makes gallon pitcher iced tea purchase \n",
      "Original summary: excellent flavor \n",
      "Predicted summary:  great tea\n",
      "\n",
      "\n",
      "Review: product perfect someone eats sugar xylitol wonderful alternative sugar unlike sugar actually health benefits consuming xylitol \n",
      "Original summary: excellent alternative \n",
      "Predicted summary:  great sugar free candy\n",
      "\n",
      "\n",
      "Review: getting fresh pressed pomegranate juice little bucks per bottle please \n",
      "Original summary: rip off \n",
      "Predicted summary:  not what expected\n",
      "\n",
      "\n",
      "Review: beef jerky lovers like jerky best tasting stuff ive found anywhere flavors great black peppered opinion best wood smoked little dry still good would recommend anybody \n",
      "Original summary: great stuff \n",
      "Predicted summary:  great jerky\n",
      "\n",
      "\n",
      "Review: keebler chips deluxe coconut ounce packages cookies great someone amazon shipping department took pack received packs paid eight package shame \n",
      "Original summary: amazon pack of my cookies \n",
      "Predicted summary:  great cookies\n",
      "\n",
      "\n",
      "Review: product satisfying crave flavor without calories use two tablets mug coffee perfect use less convenient size tablets flavor right highly recommend love vanilla flavored coffee calories \n",
      "Original summary: delicious \n",
      "Predicted summary:  best coffee\n",
      "\n",
      "\n",
      "Review: glad found product lactose intolerant regular milk anyway tried soy like taste rice dream rice milk truly dream glad found tried love eat \n",
      "Original summary: love it \n",
      "Predicted summary:  great for cooking\n",
      "\n",
      "\n",
      "Review: love candies sister got sees present shared buy often soft middle almonds yummy \n",
      "Original summary: yummy \n",
      "Predicted summary:  yummy\n",
      "\n",
      "\n",
      "Review: great flavor trust stuff delivers exactly says get ice bath ready wear loose \n",
      "Original summary: the best of the hot sauces \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: grade much richer maple flavor grade tasted quite treat weekend family breakfast highly recommend \n",
      "Original summary: excellent \n",
      "Predicted summary:  great syrup\n",
      "\n",
      "\n",
      "Review: bought bulbs use laundry room better spot stains living better light dark winter days well pleased \n",
      "Original summary: product that is all as \n",
      "Predicted summary:  good product\n",
      "\n",
      "\n",
      "Review: husband loves starbucks sumatra cup samples bold coffee keurig tried far favorite right amount flavor strength taste \n",
      "Original summary: bold and full of flavor good flavor \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: light grassy smoke tone drink without adding sweetener milk \n",
      "Original summary: fine cup of tea \n",
      "Predicted summary:  not what expected\n",
      "\n",
      "\n",
      "Review: different kinds cookies one rocks would never know gluten free \n",
      "Original summary: great tasting \n",
      "Predicted summary:  great cookies\n",
      "\n",
      "\n",
      "Review: used bring back italy delighted found artificial ingredients taste close home made cake commercial product put kids lunch box love afternoon dinner little treat good one also available believe \n",
      "Original summary: mix \n",
      "Predicted summary:  great for lunch\n",
      "\n",
      "\n",
      "Review: fewer fewer stores carry loose leaf tea glad find amazon knew become avid fan amazon last months wonderful someone else shopping allows find products one place \n",
      "Original summary: lipton loose leaf tea \n",
      "Predicted summary:  great tea\n",
      "\n",
      "\n",
      "Review: tried coffee working early morning job one best coffees ever tried flavor warm strong left wanting one cup go starbucks time honestly thought coffee better definitely recommend \n",
      "Original summary: amazing coffee \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: use hour energy replacement coffee coffee irritating throat eliminated desire drink coffee hour energy berry ounce bottles \n",
      "Original summary: hour coffee \n",
      "Predicted summary:  good coffee\n",
      "\n",
      "\n",
      "Review: dogs love antlers much cheaper antlers available amazon doggies love easily get perhaps last antlers hand hold dogs attention longer antlers extremely happy product continue order \n",
      "Original summary: doggie crack \n",
      "Predicted summary:  dogs love it\n",
      "\n",
      "\n",
      "Review: purchasing gluten free snack bars several years finding great price wonderful mention free shipping auto signed complaints far easier cheaper going store every week \n",
      "Original summary: great price for product use \n",
      "Predicted summary:  great gluten free snack\n",
      "\n",
      "\n",
      "Review: children love rice milk boxes right size lunches \n",
      "Original summary: great for lunches \n",
      "Predicted summary:  great for baby\n",
      "\n",
      "\n",
      "Review: thin bad tasting honey non natural smell strange taste high fructose corn syrup honey meets description wonder cheap \n",
      "Original summary: honey \n",
      "Predicted summary:  not that great\n",
      "\n",
      "\n",
      "Review: bold rich love coffee fast wake morning pick mid day name perfectly suited delightful brew must store airtight container opening plastic bags though coffee lose potency \n",
      "Original summary: coffee \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: husband celiac tied several bread mixes best one found freezes well best taste use bread machine \n",
      "Original summary: good bread mix \n",
      "Predicted summary:  best bread mix\n",
      "\n",
      "\n",
      "Review: like tea fruity even expected almost berry like taste take time regret bought tea good one around \n",
      "Original summary: very fruity \n",
      "Predicted summary:  great tea\n",
      "\n",
      "\n",
      "Review: great idea disappointing quality markers dried difficult use pens would write paper clearly would act dry rolled fondant seller great shipped early enough time opt plan \n",
      "Original summary: poor quality \n",
      "Predicted summary:  not what expected\n",
      "\n",
      "\n",
      "Review: husband love good pasta great tasting try pasta pesto surprise taste inside enjoyed much \n",
      "Original summary: love this pasta \n",
      "Predicted summary:  great pasta\n",
      "\n",
      "\n",
      "Review: tried every local edible writing markers none number colors worked well order online get well worth great cake pops \n",
      "Original summary: great product \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: great easy fix soup add ham onions barley cut sodium abit add extra cups water seems trick enjoy \n",
      "Original summary: umm umm good \n",
      "Predicted summary:  great soup\n",
      "\n",
      "\n",
      "Review: chile good green chile flavor heat use kick super hot powder got trick \n",
      "Original summary: good flavor \n",
      "Predicted summary:  good stuff\n",
      "\n",
      "\n",
      "Review: bought present wife loves seemed like better option salt samplers super small amounts enough salts hundreds dishes \n",
      "Original summary: love it \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: always made pancake waffle mix pre made stuff tried mix one person really liked heavy cornmeal taste back recipe \n",
      "Original summary: does not our taste \n",
      "Predicted summary:  great pancakes\n",
      "\n",
      "\n",
      "Review: contrary previously purchased twix size package ordered shipped together fresh tasting great cup coffee good value money \n",
      "Original summary: kit kat candy bar ct \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: love tea vanilla flavors favorite type tea one favorite vanilla caramel flavors blend really well \n",
      "Original summary: great tasting dessert tea \n",
      "Predicted summary:  great tea\n",
      "\n",
      "\n",
      "Review: wish noticed list ingredients purchased product cheese read ingredients msg bad ingredients besides cheese yuck throw taste great either \n",
      "Original summary: not that great \n",
      "Predicted summary:  stale\n",
      "\n",
      "\n",
      "Review: wow amazingly tasty addictive even wish easier find \n",
      "Original summary: so tasty \n",
      "Predicted summary:  yummy\n",
      "\n",
      "\n",
      "Review: chose product great reviews good ok \n",
      "Original summary: it is just ok \n",
      "Predicted summary:  great taste\n",
      "\n",
      "\n",
      "Review: favorite side dish kids easy prepare makes great filling stuffed peppers \n",
      "Original summary: the kids love this \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: family love rice every time served company want know kind rice make chicken broth rather water enhance flavor \n",
      "Original summary: royal blend rice \n",
      "Predicted summary:  rice\n",
      "\n",
      "\n",
      "Review: great calories however kinda pricey noodles buy size get better deal online asian stores edit go local asian grocery store super cheap per bag \n",
      "Original summary: great product but kind of pricey \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: simple cook nice cheesy kids enjoyed change plain old macaroni cheese like add veggies \n",
      "Original summary: cheesy good \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: happy quality peppercorns good buy much better get co op \n",
      "Original summary: great price and service \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: tender light popcorn use back stainless steel stove top popcorn popper \n",
      "Original summary: fresh and light popcorn \n",
      "Predicted summary:  great popcorn\n",
      "\n",
      "\n",
      "Review: nice tree smaller thought probably read see size buying gift dad loved \n",
      "Original summary: great little tree \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: favorite tea regular green tea tastes little bitter addition brown rice gives tea nice smokey flavor winter drink least two cups day cannot get enough \n",
      "Original summary: yummy \n",
      "Predicted summary:  great tea\n",
      "\n",
      "\n",
      "Review: yeah alright usual standard rice crackers peas peanuts wasabi sesame sticks quality fine hoping little variety costco seems stopped carrying oriental mix looking replacement product though \n",
      "Original summary: it is ok \n",
      "Predicted summary:  not for kids\n",
      "\n",
      "\n",
      "Review: cups sweetened sucralose realize tried one ended little bit headache made check ingredient list noted front box definitely artificial taste would buy \n",
      "Original summary: artificial taste \n",
      "Predicted summary:  not that great\n",
      "\n",
      "\n",
      "Review: cooks microwave fast really good right cook unfortunately msg nonetheless fat sodium content bad compared regular pork rinds photo nutrition facts see ingredients \n",
      "Original summary: so tasty but has msg \n",
      "Predicted summary:  not as good as the picture\n",
      "\n",
      "\n",
      "Review: seeds grow easy one seed pack grew little pots would grow using seeds every days separate little pots cats never without great buy \n",
      "Original summary: they grow easy \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: love product works well keeping hydrated training runs stomach count help things little hydrate even attest treating hangover highly recommend quick shipping good price vendor \n",
      "Original summary: this stuff rocks \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: fabulous little red pearls even better craisins plump juicy perfect banana bread semi tart cherry flavor body taste buy great surprise \n",
      "Original summary: yum \n",
      "Predicted summary:  pamela bread mix\n",
      "\n",
      "\n",
      "Review: use love getting gum kid loved colors shape diffrent normal bubble gum piece dont long flavor lasted really tasty \n",
      "Original summary: amazing gum \n",
      "Predicted summary:  not the best\n",
      "\n",
      "\n",
      "Review: coffee awesome like bold stout coffee disappoint smells great like weak mild coffee may \n",
      "Original summary: awesome \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: poured great wine type yeast used make sweet red alcohol content produced around much little great product \n",
      "Original summary: made some great wine \n",
      "Predicted summary:  good product\n",
      "\n",
      "\n",
      "Review: noodles low carb taste great arrived un crushed concern buying amazon \n",
      "Original summary: great buy \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: received fast hot chocolate yummy put couple marshmallows top feel warm cozy satisfied \n",
      "Original summary: delicious \n",
      "Predicted summary:  great hot chocolate\n",
      "\n",
      "\n",
      "Review: dogswell happy hips dogs chicken breast ounce pouches dogswell chicken jerky made china fda warned dog food products made china risk \n",
      "Original summary: dogswell is now made in china \n",
      "Predicted summary:  not for dogs\n",
      "\n",
      "\n",
      "Review: kids eat quickly pack bunnies instead chips lunch without complaints kids \n",
      "Original summary: kids like them \n",
      "Predicted summary:  great snack\n",
      "\n",
      "\n",
      "Review: bought gum third grade students wrote blow bubble chewing sugarless bubble yum loved taste gum flavor good \n",
      "Original summary: great flavored gum \n",
      "Predicted summary:  great gum\n",
      "\n",
      "\n",
      "Review: favorite chocolate treats especially good designed flamingo great tasting fun packaging made nice gift caring neighbors \n",
      "Original summary: good eats \n",
      "Predicted summary:  great cookies\n",
      "\n",
      "\n",
      "Review: ordering oil quite time still think best evoo ever tasted fruity aftertaste delicious front tounge well sticking oil long get \n",
      "Original summary: great \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: bars really best bars beat combination mangos plus macadamias plus coconut cannot sweet like product \n",
      "Original summary: warning so good you will get fat \n",
      "Predicted summary:  great bars\n",
      "\n",
      "\n",
      "Review: husband gluten intolerant love rice noodles substitute hold well boiling used everything spaghetti fettucini stir fry even kids love \n",
      "Original summary: multi purpose noodles \n",
      "Predicted summary:  great gluten free pasta\n",
      "\n",
      "\n",
      "Review: ah dubble bubble starts really hard flavor last long blow amazing bubbles great bucket get stuffing keep around sure delight kids nostalgic adults \n",
      "Original summary: just like remember \n",
      "Predicted summary:  great tasting snack\n",
      "\n",
      "\n",
      "Review: use clean veggies especially fresh basil leaves basil fragile leaves turn dark quickly washed using citric acid change color freshness know really working \n",
      "Original summary: very good \n",
      "Predicted summary:  great taste\n",
      "\n",
      "\n",
      "Review: bbq sauce absolutely delicious shared friends buying \n",
      "Original summary: delicious dr pepper bbq sauce \n",
      "Predicted summary:  great sauce\n",
      "\n",
      "\n",
      "Review: love easily intense tried current supply runs order \n",
      "Original summary: altoids spearmint mints \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: product works need instant whether sleep deprived \n",
      "Original summary: wake up \n",
      "Predicted summary:  hour energy\n",
      "\n",
      "\n",
      "Review: right amount oil right amount salt comes convenience simply able beat pack \n",
      "Original summary: right \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: son like first taste got used loved sure much better others organic label got buy mixed milk fruit great breakfast son looks forward every morning \n",
      "Original summary: awesome deal \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: kitty went nuts first opened kept running around legs looking source cannot enough em thankfully organic could much wants worry diabetes diarrhea \n",
      "Original summary: went nuts \n",
      "Predicted summary:  my cats love this\n",
      "\n",
      "\n",
      "Review: children sensitivities many food ingredients including cane sugar thrilled find cookie like contain yuck find traditional cookies \n",
      "Original summary: great animal crackers \n",
      "Predicted summary:  great cookies\n",
      "\n",
      "\n",
      "Review: dark chocolate candy covers center blueberry acai peanut butter prominent tasty wish chocolate covering dense gets hands hot weather \n",
      "Original summary: dark chocolate \n",
      "Predicted summary:  dark chocolate\n",
      "\n",
      "\n",
      "Review: would buy chia seeds costco instead pounds use smoothies salads lately mix chocolate almond milk amazing pudding hours chilled \n",
      "Original summary: awesome \n",
      "Predicted summary:  delicious\n",
      "\n",
      "\n",
      "Review: love snacks grandpa po originals great snack satisfy hunger craving crunchy great flavor hard stop eating whole bag one sitting \n",
      "Original summary: love snacks \n",
      "Predicted summary:  great snack\n",
      "\n",
      "\n",
      "Review: wonderful flavor full easily vitamins minerals son allergic dairy except ghee well product organic grass fed wish could buy locally cut packaging though \n",
      "Original summary: great product that wish could buy locally \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: hawaiian shaved ice snow cone syrups flavor pack great business courteous super fast response buy \n",
      "Original summary: hawaiian ice cone syrups flavor pack \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: great service fast ordered item tasted great fresh trouble shipping fault extremely helpful pleasure deal \n",
      "Original summary: wonderful service great \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: expensive worth buying much next opportunity buy unfortunately brazil bought excellent buttery impossible eat one box satisfied want walkers shortbread assorted boxes \n",
      "Original summary: bought very little but prices are not good \n",
      "Predicted summary:  not as good as expected\n",
      "\n",
      "\n",
      "Review: like lot great taste sweet perfect way start day \n",
      "Original summary: good stuff \n",
      "Predicted summary:  great taste\n",
      "\n",
      "\n",
      "Review: chocolates best unfortunately easy find us european product fresh tasted amazing \n",
      "Original summary: delish \n",
      "Predicted summary:  best ever\n",
      "\n",
      "\n",
      "Review: enough english language describe good mom loves coconut made th birthday loved love love cupcake going try coconut cake next time \n",
      "Original summary: eating one right now \n",
      "Predicted summary:  great gift\n",
      "\n",
      "\n",
      "Review: like flavor much cheaper pay work really like convenience case \n",
      "Original summary: yummy \n",
      "Predicted summary:  good but not great\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100):\n",
    "    print(\"Review:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OTkaYNjHW4lC"
   },
   "source": [
    "This is really cool stuff. Even though the actual summary and the summary generated by our model do not match in terms of words, both of them are conveying the same meaning. Our model is able to generate a legible summary based on the context present in the text.\n",
    "\n",
    "This is how we can perform text summarization using deep learning concepts in Python.\n",
    "\n",
    "#How can we Improve the Model’s Performance Even Further?\n",
    "\n",
    "Your learning doesn’t stop here! There’s a lot more you can do to play around and experiment with the model:\n",
    "\n",
    "I recommend you to **increase the training dataset** size and build the model. The generalization capability of a deep learning model enhances with an increase in the training dataset size\n",
    "\n",
    "Try implementing **Bi-Directional LSTM** which is capable of capturing the context from both the directions and results in a better context vector\n",
    "\n",
    "Use the **beam search strategy** for decoding the test sequence instead of using the greedy approach (argmax)\n",
    "\n",
    "Evaluate the performance of your model based on the **BLEU score**\n",
    "\n",
    "Implement **pointer-generator networks** and **coverage mechanisms**\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_qIecuvY5GT"
   },
   "source": [
    "#End Notes\n",
    "\n",
    "If you have any feedback on this article or any doubts/queries, kindly share them in the comments section over [here](https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/) and I will get back to you. And make sure you experiment with the model we built here and share your results with me!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "How to build own text summarizer using deep learning.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:TXTSUMG] *",
   "language": "python",
   "name": "conda-env-TXTSUMG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
